{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSeSET8fI5cRy3iWKS8/Je",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhitha0714/AIAC/blob/main/NLP_2403A52084_assignment_6_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Title: Sequence Modeling with HMMs for Technical Text Dataset Source:\n",
        "\n",
        "o POS-tagged sample abstracts\n",
        "\n",
        "o (Abstracts sourced from arXiv via Kaggle)\n",
        "\n",
        "Lab Objectives:\n",
        "\n",
        "o Understand domain mismatch in HMMs\n",
        "\n",
        "o Analyze tag transition patterns in technical writing\n",
        "\n",
        "Tasks:\n",
        "\n",
        "o Collect 20–30 research abstracts.\n",
        "\n",
        "o Automatically POS-tag them using NLTK.\n",
        "\n",
        "o Treat the tagged data as training data for HMM.\n",
        "\n",
        "Compute:\n",
        "\n",
        "o Transition probabilities\n",
        "\n",
        "o Emission probabilities\n",
        "\n",
        "o Analyze:\n",
        "\n",
        "o Most frequent tag transitions\n",
        "\n",
        "o Apply HMM tagging to a new abstract sentence."
      ],
      "metadata": {
        "id": "6DHThVJ2ctcy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHwjZyuvcjC1",
        "outputId": "8626857c-4869-49ce-b46e-0b521d494df3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "abstracts = [\n",
        "    \"This paper proposes a novel deep learning architecture for image classification tasks using convolutional neural networks.\",\n",
        "    \"We investigate optimization techniques for training large scale neural networks efficiently.\",\n",
        "    \"Experimental results demonstrate significant improvements over existing state of the art methods.\",\n",
        "    \"The proposed approach leverages attention mechanisms for sequence modeling in natural language processing.\",\n",
        "    \"This study presents a comparative analysis of machine learning algorithms for predictive analytics.\",\n",
        "    \"We introduce a hybrid model combining statistical learning and neural representations.\",\n",
        "    \"The algorithm achieves high accuracy on benchmark datasets across multiple domains.\",\n",
        "    \"A probabilistic framework is developed for modeling uncertainty in classification systems.\",\n",
        "    \"This work explores feature extraction techniques for high dimensional data.\",\n",
        "    \"The proposed method improves convergence speed during model training.\",\n",
        "    \"We analyze the performance of supervised learning techniques in noisy environments.\",\n",
        "    \"A scalable architecture is designed for real time data processing applications.\",\n",
        "    \"The results indicate robustness and stability of the proposed system.\",\n",
        "    \"This paper discusses challenges in deploying deep learning models in production systems.\",\n",
        "    \"A novel loss function is introduced to enhance classification performance.\",\n",
        "    \"The framework integrates domain knowledge into neural network training.\",\n",
        "    \"We evaluate the model using standard evaluation metrics and datasets.\",\n",
        "    \"The proposed solution reduces computational complexity significantly.\",\n",
        "    \"This research focuses on transfer learning techniques for limited data scenarios.\",\n",
        "    \"An efficient algorithm is presented for large scale text classification.\",\n",
        "    \"The experimental setup includes cross validation and hyperparameter tuning.\",\n",
        "    \"The system demonstrates improved generalization on unseen data.\",\n",
        "    \"This work addresses scalability issues in distributed machine learning.\",\n",
        "    \"A comprehensive evaluation is conducted using real world datasets.\",\n",
        "    \"The model outperforms baseline approaches in terms of accuracy and efficiency.\"\n",
        "]\n",
        "\n",
        "len(abstracts)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Automatically POS-tag them using NLTK.\n",
        "\n"
      ],
      "metadata": {
        "id": "THU58W_MczZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt_tab') # Add download for punkt_tab\n",
        "except LookupError:\n",
        "    nltk.download('punkt_tab')\n",
        "\n",
        "try:\n",
        "    nltk.data.find('taggers/averaged_perceptron_tagger_eng') # Changed to specific English version\n",
        "except LookupError:\n",
        "    nltk.download('averaged_perceptron_tagger_eng') # Corrected to download the specific English version\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "tagged_sentences = []\n",
        "\n",
        "for abstract in abstracts:\n",
        "    tokens = word_tokenize(abstract)   # Tokenize sentence\n",
        "    tagged = pos_tag(tokens)           # POS tagging\n",
        "    tagged_sentences.append(tagged)\n",
        "display(tagged_sentences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "xdAKc--Vcyou",
        "outputId": "4e494460-9326-4676-f4be-910ce820e079"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[('This', 'DT'),\n",
              " ('paper', 'NN'),\n",
              " ('proposes', 'VBZ'),\n",
              " ('a', 'DT'),\n",
              " ('novel', 'JJ'),\n",
              " ('deep', 'JJ'),\n",
              " ('learning', 'NN'),\n",
              " ('architecture', 'NN'),\n",
              " ('for', 'IN'),\n",
              " ('image', 'NN'),\n",
              " ('classification', 'NN'),\n",
              " ('tasks', 'NNS'),\n",
              " ('using', 'VBG'),\n",
              " ('convolutional', 'JJ'),\n",
              " ('neural', 'JJ'),\n",
              " ('networks', 'NNS'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Treat the tagged data as training data for HMM\n"
      ],
      "metadata": {
        "id": "J7wzteBaeQTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[\n",
        "  [('This','DT'), ('paper','NN'), ('proposes','VBZ'), ...],\n",
        "  [('We','PRP'), ('investigate','VBP'), ...],\n",
        "  ...\n",
        "]\n",
        "from nltk.tag import hmm\n",
        "trainer = hmm.HiddenMarkovModelTrainer()\n",
        "hmm_tagger = trainer.train(tagged_sentences)\n",
        "print(type(hmm_tagger))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzMxHSUSeP7b",
        "outputId": "0d67c496-c198-4edb-821a-9d1c805d2c77"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'nltk.tag.hmm.HiddenMarkovModelTagger'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Compute:\n",
        "\n",
        "a.Transition probabilities"
      ],
      "metadata": {
        "id": "j30GLm12eZXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hmm_tagger\n",
        "transitions = hmm_tagger._transitions\n",
        "print(\"P(JJ → NN):\", transitions['JJ'].prob('NN'))\n",
        "print(\"P(NN → NN):\", transitions['NN'].prob('NN'))\n",
        "print(\"P(DT → JJ):\", transitions['DT'].prob('JJ'))\n",
        "print(\"P(IN → NN):\", transitions['IN'].prob('NN'))\n",
        "for tag1 in ['JJ', 'NN', 'DT']:\n",
        "    for tag2 in ['NN', 'JJ', 'IN']:\n",
        "        print(f\"P({tag1} → {tag2}) = {transitions[tag1].prob(tag2)}\")\n",
        "import pandas as pd\n",
        "\n",
        "tags = list(transitions.keys())\n",
        "matrix = []\n",
        "\n",
        "for t1 in tags:\n",
        "    row = []\n",
        "    for t2 in tags:\n",
        "        row.append(transitions[t1].prob(t2))\n",
        "    matrix.append(row)\n",
        "\n",
        "transition_matrix = pd.DataFrame(matrix, index=tags, columns=tags)\n",
        "transition_matrix.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "b3CP5ve1eaLg",
        "outputId": "e36e8663-e4c4-438c-d63b-898083ef5707"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(JJ → NN): 0.5227272727272727\n",
            "P(NN → NN): 0.19736842105263158\n",
            "P(DT → JJ): 0.3333333333333333\n",
            "P(IN → NN): 0.32142857142857145\n",
            "P(JJ → NN) = 0.5227272727272727\n",
            "P(JJ → JJ) = 0.1590909090909091\n",
            "P(JJ → IN) = 0.0\n",
            "P(NN → NN) = 0.19736842105263158\n",
            "P(NN → JJ) = 0.0\n",
            "P(NN → IN) = 0.15789473684210525\n",
            "P(DT → NN) = 0.48148148148148145\n",
            "P(DT → JJ) = 0.3333333333333333\n",
            "P(DT → IN) = 0.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           DT        NN   VBZ        JJ        IN       NNS       VBG  PRP  \\\n",
              "DT   0.000000  0.481481  0.00  0.333333  0.000000  0.037037  0.000000  0.0   \n",
              "NN   0.000000  0.197368  0.25  0.000000  0.157895  0.184211  0.026316  0.0   \n",
              "VBZ  0.105263  0.105263  0.00  0.368421  0.052632  0.052632  0.000000  0.0   \n",
              "JJ   0.000000  0.522727  0.00  0.159091  0.000000  0.295455  0.022727  0.0   \n",
              "IN   0.071429  0.321429  0.00  0.428571  0.000000  0.035714  0.142857  0.0   \n",
              "\n",
              "          VBP        RB       VBN        CC   TO   VB  \n",
              "DT   0.000000  0.000000  0.148148  0.000000  0.0  0.0  \n",
              "NN   0.000000  0.013158  0.000000  0.052632  0.0  0.0  \n",
              "VBZ  0.052632  0.000000  0.263158  0.000000  0.0  0.0  \n",
              "JJ   0.000000  0.000000  0.000000  0.000000  0.0  0.0  \n",
              "IN   0.000000  0.000000  0.000000  0.000000  0.0  0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4d60f37-8f17-4b68-8ae3-f7691d00d05d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DT</th>\n",
              "      <th>NN</th>\n",
              "      <th>VBZ</th>\n",
              "      <th>JJ</th>\n",
              "      <th>IN</th>\n",
              "      <th>NNS</th>\n",
              "      <th>VBG</th>\n",
              "      <th>PRP</th>\n",
              "      <th>VBP</th>\n",
              "      <th>RB</th>\n",
              "      <th>VBN</th>\n",
              "      <th>CC</th>\n",
              "      <th>TO</th>\n",
              "      <th>VB</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>DT</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.481481</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.037037</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.148148</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NN</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.197368</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.157895</td>\n",
              "      <td>0.184211</td>\n",
              "      <td>0.026316</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013158</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>VBZ</th>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.263158</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>JJ</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.522727</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.159091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.295455</td>\n",
              "      <td>0.022727</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>IN</th>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.321429</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4d60f37-8f17-4b68-8ae3-f7691d00d05d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b4d60f37-8f17-4b68-8ae3-f7691d00d05d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b4d60f37-8f17-4b68-8ae3-f7691d00d05d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "transition_matrix",
              "summary": "{\n  \"name\": \"transition_matrix\",\n  \"rows\": 14,\n  \"fields\": [\n    {\n      \"column\": \"DT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1340133159004964,\n        \"min\": 0.0,\n        \"max\": 0.5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.10526315789473684,\n          0.5,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2931898989970869,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.6,\n          0.4444444444444444,\n          0.48148148148148145\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"VBZ\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06681531047810607,\n        \"min\": 0.0,\n        \"max\": 0.25,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.25,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"JJ\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21478832477119184,\n        \"min\": 0.0,\n        \"max\": 0.6666666666666666,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.0,\n          0.030303030303030304\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12776734191559816,\n        \"min\": 0.0,\n        \"max\": 0.36363636363636365,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.15789473684210525,\n          0.3333333333333333\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NNS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09443074642071247,\n        \"min\": 0.0,\n        \"max\": 0.29545454545454547,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          0.0,\n          0.18421052631578946\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"VBG\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04552730524592717,\n        \"min\": 0.0,\n        \"max\": 0.14285714285714285,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.0,\n          0.02631578947368421\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PRP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"VBP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.26601340157267467,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.05263157894736842\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RB\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008577635675101624,\n        \"min\": 0.0,\n        \"max\": 0.030303030303030304,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"VBN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07801192703102229,\n        \"min\": 0.0,\n        \"max\": 0.2631578947368421,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.14814814814814814\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01568208277352157,\n        \"min\": 0.0,\n        \"max\": 0.05263157894736842,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TO\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02969569354582493,\n        \"min\": 0.0,\n        \"max\": 0.1111111111111111,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.1111111111111111\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"VB\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2672612419124244,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Emission probabilities"
      ],
      "metadata": {
        "id": "0aAKCG4VefAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emissions = hmm_tagger._outputs\n",
        "print(\"Emission Probabilities:\")\n",
        "print(\"P('model' | NN):\", emissions['NN'].prob('model'))\n",
        "print(\"P('neural' | JJ):\", emissions['JJ'].prob('neural'))\n",
        "print(\"P('achieves' | VBZ):\", emissions['VBZ'].prob('achieves'))\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WWoUxuyefmi",
        "outputId": "c8b8906b-643e-4fc6-a5d6-b5f14ebd684d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emission Probabilities:\n",
            "P('model' | NN): 0.05263157894736842\n",
            "P('neural' | JJ): 0.09090909090909091\n",
            "P('achieves' | VBZ): 0.05263157894736842\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c.Analyze: Most frequent tag transitions"
      ],
      "metadata": {
        "id": "6-C7F7kxekmt"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcd08564",
        "outputId": "3061ef8f-7eea-4120-9802-39416374c4bf"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "transition_counts = Counter()\n",
        "for sent in tagged_sentences:\n",
        "    for i in range(len(sent) - 1):\n",
        "        transition_counts[(sent[i][1], sent[i+1][1])] += 1\n",
        "\n",
        "print(\"Most Frequent POS Tag Transitions:\")\n",
        "for pair, count in transition_counts.most_common(5):\n",
        "    print(pair, \":\", count)\n",
        "print()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Frequent POS Tag Transitions:\n",
            "('JJ', 'NN') : 23\n",
            "('NN', 'VBZ') : 19\n",
            "('NN', 'NN') : 15\n",
            "('NN', 'NNS') : 14\n",
            "('NNS', '.') : 14\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d.Apply HMM tagging to a new abstract sentence"
      ],
      "metadata": {
        "id": "1Z4ggfQGfMac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = \"The proposed model achieves high accuracy on benchmark datasets\"\n",
        "tokens = word_tokenize(test_sentence)\n",
        "tagged_output = hmm_tagger.tag(tokens)\n",
        "\n",
        "print(\"HMM Tagging Output:\")\n",
        "print(tagged_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bONhjBGjfNBm",
        "outputId": "6b58deb4-9424-419c-e1e0-02aa0f14312f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HMM Tagging Output:\n",
            "[('The', 'DT'), ('proposed', 'VBN'), ('model', 'NN'), ('achieves', 'VBZ'), ('high', 'JJ'), ('accuracy', 'NN'), ('on', 'IN'), ('benchmark', 'NN'), ('datasets', 'NNS')]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/nltk/tag/hmm.py:333: RuntimeWarning: overflow encountered in cast\n",
            "  X[i, j] = self._transitions[si].logprob(self._states[j])\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/tag/hmm.py:335: RuntimeWarning: overflow encountered in cast\n",
            "  O[i, k] = self._output_logprob(si, self._symbols[k])\n",
            "/usr/local/lib/python3.12/dist-packages/nltk/tag/hmm.py:331: RuntimeWarning: overflow encountered in cast\n",
            "  P[i] = self._priors.logprob(si)\n"
          ]
        }
      ]
    }
  ]
}